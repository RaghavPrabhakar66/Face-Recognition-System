import cv2
import torch as T
import torchvision.transforms as transforms
from facenet_pytorch import InceptionResnetV1

model = InceptionResnetV1(pretrained='vggface2').eval()
img = cv2.imread('data/database/dhruv.png')
img = T.from_numpy(img)
embeds = model(img.unsqueeze(-1))
print(embeds)
# class InceptionResnetRecognizer():
#     def __init__(self, database):
#         self.embed = face_recognition.face_encodings
#         self.compare = face_recognition.compare_faces
#         self.dist = face_recognition.face_distance
#         self.database_embeddings = [self.embed(image)[0] for (_, image) in database]
#         self.database = database

#     def recognize(self, face):
#         face_embeddings = self.embed(face)
#         if not face_embeddings:
#             return None, None
#         matches = self.compare(self.database_embeddings, face_embeddings[0])
#         dists = face_recognition.face_distance(self.database_embeddings, face_embeddings[0])
#         index = np.argmin(dists)

#         if matches[index]:
#             return self.database[index]
#         else:
#             return None, None
